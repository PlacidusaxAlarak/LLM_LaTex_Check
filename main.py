

# main.py

import os
import asyncio
import re
from datetime import datetime
from dotenv import load_dotenv
from typing import List, Dict, Any
import llm_agent
import latex_parser
import file_writer
import archive_handler

# --- é…ç½® ---
SOURCE_ARCHIVE_PATH = 'latex_source.gz'
EXTRACT_DIR = './data'
OUTPUT_HTML_FILE = 'references_analysis_report.html'
# MODIFIED: å°†æ‰¹å¤„ç†å¤§å°è®¾ä¸º1ï¼Œä¸ºæ¯ä¸ªå‚è€ƒæ–‡çŒ®åˆ›å»ºä¸€ä¸ªç‹¬ç«‹çš„å¹¶å‘ä»»åŠ¡
BATCH_SIZE = 1
REFERENCE_PARSING_BATCH_SIZE = 1

# --- HTML æ¨¡æ¿ ---
HTML_HEADER = """
<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>å‚è€ƒæ–‡çŒ®åˆ†ææŠ¥å‘Š - {title}</title>
    <style>
        body {{
            font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, "Helvetica Neue", Arial, sans-serif;
            line-height: 1.6; color: #333; background-color: #f8f9fa; margin: 0; padding: 20px;
        }}
        .container {{
            max-width: 900px; margin: 0 auto; background-color: #fff; padding: 2rem;
            border-radius: 8px; box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);
        }}
        h1, h2, h3 {{ color: #0056b3; }}
        h1 {{ border-bottom: 2px solid #dee2e6; padding-bottom: 0.5rem; margin-bottom: 1rem; text-align: center; }}
        h2 em {{ font-weight: normal; color: #555; font-size: 0.8em; }}
        .reference-item {{
            margin-bottom: 2rem; padding: 1.5rem; border: 1px solid #e9ecef;
            border-radius: 6px; background-color: #ffffff; transition: box-shadow 0.3s ease;
        }}
        .reference-item:hover {{ box-shadow: 0 8px 16px rgba(0,0,0,0.1); }}
        blockquote {{
            margin: 0; padding: 1rem; background-color: #f8f9fa; border-left: 5px solid #007bff;
        }}
        ul {{ padding-left: 20px; }}
        li {{ margin-bottom: 0.5rem; }}
        code {{ background-color: #e9ecef; color: #d63384; padding: 2px 4px; border-radius: 3px; }}
        .citation-context li strong:first-child {{ color: #28a745; }} /* ç« èŠ‚, å‰æ–‡, etc. */
        .citation-context strong {{ color: #d9534f; /* é«˜äº®å¼•æ–‡å‘½ä»¤ */ }}
        .footer {{ text-align: center; margin-top: 2rem; font-size: 0.9em; color: #6c757d; }}
    </style>
</head>
<body>
    <div class="container">
        <h1>å‚è€ƒæ–‡çŒ®ä¸Šä¸‹æ–‡åˆ†ææŠ¥å‘Š</h1>
        <h2>è®ºæ–‡: <em>{title}</em></h2>
"""

HTML_FOOTER = """
    </div>
    <div class="footer">
        <p>æŠ¥å‘Šç”Ÿæˆäº: {timestamp}</p>
    </div>
</body>
</html>
"""


def extract_paper_title(latex_content: str) -> str:
    """ä»LaTeXæºç ä¸­æå–è®ºæ–‡æ ‡é¢˜ã€‚"""
    match = re.search(r'\\title\{([^}]+)\}', latex_content, re.DOTALL)
    if match:
        # æ¸…ç†å¸¸è§çš„LaTeXæ¢è¡Œç¬¦å’Œå…¶ä»–å‘½ä»¤
        title = match.group(1).replace('\\\\', ' ').replace('\n', ' ').strip()
        return re.sub(r'\s+', ' ', title)
    return "æœªæ‰¾åˆ°æ ‡é¢˜"


def render_html_from_data(all_references_data: list[dict]) -> str:
    """ä»LLMè¿”å›çš„ç»“æ„åŒ–æ•°æ®åˆ—è¡¨ä¸­æ¸²æŸ“HTMLå†…å®¹ã€‚"""
    html_parts = []
    # æŒ‰IDæ’åºä»¥ä¿æŒåŸå§‹å‚è€ƒæ–‡çŒ®é¡ºåº
    sorted_data = sorted(all_references_data, key=lambda x: x.get('id', 0))

    for item in sorted_data:
        key = item.get("key", "N/A")
        # ä¼˜åŒ–æ ‡é¢˜å’Œä½œè€…çš„è·å–é€»è¾‘
        title = item.get("inferred_title", item.get("title", "N/A"))
        author = item.get("inferred_author", "ä½œè€…ä¿¡æ¯æœªæå–")
        source = item.get("inferred_source", item.get("content", ""))

        item_html = f'<div class="reference-item">\n'
        item_html += f'    <h3>å‚è€ƒæ–‡çŒ®: <code>{key}</code></h3>\n'
        item_html += f'    <blockquote>\n'
        item_html += f'        <p><strong>ä½œè€…:</strong> {author}</p>\n'
        item_html += f'        <p><strong>æ ‡é¢˜:</strong> {title}</p>\n'
        item_html += f'        <p><strong>æ¥æº:</strong> {source}</p>\n'
        item_html += f'    </blockquote>\n'
        item_html += '    <h4>å¼•ç”¨ä½ç½®:</h4>\n'

        if item.get("analysis_failed"):
            item_html += '<p><em style="color: red;">æ­¤å‚è€ƒæ–‡çŒ®çš„ä¸Šä¸‹æ–‡åˆ†æå¤±è´¥ï¼ˆå¯èƒ½æ˜¯ç”±äºAPIé”™è¯¯æˆ–å†…å®¹é—®é¢˜ï¼‰ã€‚</em></p>\n'
        elif not item.get("citations"):
            item_html += '<p><em>æ­£æ–‡ä¸­æœªæ‰¾åˆ°æœ‰æ•ˆå¼•ç”¨ã€‚</em></p>\n'
        else:
            item_html += '    <ul>\n'
            for i, citation in enumerate(item.get("citations", []), 1):
                section = citation.get("section", "Unknown Section")
                pre_context = citation.get("pre_context", "")
                citation_sentence = citation.get("citation_sentence", "")
                # é«˜äº®å¼•æ–‡å‘½ä»¤
                citation_sentence_html = re.sub(
                    r'(\\(?:cite|citep|citet|Citep|Citet|citealt)\*?\{[^}]*?' + re.escape(key) + r'[^}]*?\})',
                    r'<strong>\1</strong>', citation_sentence)
                post_context = citation.get("post_context", "")

                item_html += f'        <li>\n'
                item_html += f'            <strong>ä½ç½® {i}:</strong>\n'
                item_html += f'            <ul class="citation-context">\n'
                item_html += f'                <li><strong>ç« èŠ‚:</strong> {section}</li>\n'
                item_html += f'                <li><strong>å‰æ–‡:</strong> {pre_context}</li>\n'
                item_html += f'                <li><strong>å¼•æ–‡å¥:</strong> {citation_sentence_html}</li>\n'
                item_html += f'                <li><strong>åæ–‡:</strong> {post_context}</li>\n'
                item_html += f'            </ul>\n'
                item_html += f'        </li>\n'
            item_html += '    </ul>\n'

        item_html += '</div>\n'
        html_parts.append(item_html)

    return "".join(html_parts)


async def main() -> List[Dict[str, Any]]:
    """
    ä¸»å‡½æ•°ï¼Œæ‰§è¡Œå®Œæ•´çš„ã€åŸºäºLLMçš„LaTeXå‚è€ƒæ–‡çŒ®åˆ†ææµç¨‹ã€‚
    """
    load_dotenv(".env")
    api_key = os.getenv("DEEPSEEK_API_KEY")
    if not api_key:
        print("é”™è¯¯ï¼šè¯·åœ¨.envæ–‡ä»¶ä¸­è®¾ç½®DEEPSEEK_API_KEYã€‚")
        return []

    agent = llm_agent.LLMAgent(api_key=api_key)

    try:
        # æ­¥éª¤ 1: è§£å‹å½’æ¡£æ–‡ä»¶
        print(f"æ­¥éª¤ 1: æ­£åœ¨è§£å‹ '{SOURCE_ARCHIVE_PATH}'...")
        archive_handler.extract_archive(SOURCE_ARCHIVE_PATH, EXTRACT_DIR)

        # æ­¥éª¤ 2: æ™ºèƒ½æ•´åˆLaTeXæºæ–‡ä»¶
        print("\næ­¥éª¤ 2: æ­£åœ¨æ™ºèƒ½æ•´åˆæ‰€æœ‰LaTeXæºæ–‡ä»¶...")
        full_latex_content, main_file = latex_parser.get_full_latex_source_and_main_file(EXTRACT_DIR)
        if not full_latex_content or not main_file:
            print("é”™è¯¯ï¼šæ— æ³•æ•´åˆLaTeXæºæ–‡ä»¶æˆ–æ‰¾åˆ°ä¸»æ–‡ä»¶ï¼Œæµç¨‹ä¸­æ­¢ã€‚")
            return []

        # æ­¥éª¤ 2.5: è‡ªåŠ¨æå–è®ºæ–‡æ ‡é¢˜
        paper_title = extract_paper_title(full_latex_content)
        print(f"\nâœ… è‡ªåŠ¨æå–åˆ°è®ºæ–‡æ ‡é¢˜: {paper_title}")

        # æ­¥éª¤ 3: ä½¿ç”¨LLMæ™ºèƒ½è§£æå‚è€ƒæ–‡çŒ®åˆ—è¡¨ (æ‰¹å¤„ç†æ¨¡å¼)
        print("\næ­¥éª¤ 3: æ­£åœ¨ä½¿ç”¨LLMæ™ºèƒ½è§£æå‚è€ƒæ–‡çŒ®åˆ—è¡¨ (æ‰¹å¤„ç†æ¨¡å¼)...")
        references_text_block = latex_parser.extract_raw_references_text(full_latex_content, main_file)

        bib_items_raw = re.split(r'\\bibitem', references_text_block)[1:]
        bib_items = ["\\bibitem" + item for item in bib_items_raw if item.strip()]

        if not bib_items:
            print("âŒ è‡´å‘½é”™è¯¯: æœªèƒ½ä».bblæ–‡ä»¶å†…å®¹ä¸­æ‹†åˆ†å‡ºä»»ä½• \\bibitem æ¡ç›®ã€‚")
            return []

        print(f"   â””â”€â”€ å·²å°† .bbl å†…å®¹æ‹†åˆ†ä¸º {len(bib_items)} ä¸ªç‹¬ç«‹çš„å‚è€ƒæ–‡çŒ®æ¡ç›®ã€‚")

        parsing_tasks = []
        for i in range(0, len(bib_items), REFERENCE_PARSING_BATCH_SIZE):
            batch_of_bib_items = bib_items[i:i + REFERENCE_PARSING_BATCH_SIZE]
            batch_content = "".join(batch_of_bib_items)
            print(f"  - åˆ›å»ºå‚è€ƒæ–‡çŒ®è§£ææ‰¹æ¬¡: æ¡ç›® {i + 1} åˆ° {i + len(batch_of_bib_items)}")
            task = agent.run_reference_parser(batch_content)
            parsing_tasks.append(task)

        parsed_batches = await asyncio.gather(*parsing_tasks)

        all_references = []
        for batch_result in parsed_batches:
            all_references.extend(batch_result)

        for i, ref in enumerate(all_references, 1):
            ref['id'] = i

        if not all_references:
            print("âŒ è‡´å‘½é”™è¯¯: LLMæœªèƒ½è§£æå‡ºä»»ä½•å‚è€ƒæ–‡çŒ®ã€‚å·¥ä½œæµç¨‹ä¸­æ­¢ã€‚")
            return []

        total_refs = len(all_references)
        print(f"âœ… LLMæˆåŠŸæå–å¹¶ç»“æ„åŒ–äº† {total_refs} æ¡å‚è€ƒæ–‡çŒ®åŠå…¶æ ‡é¢˜ã€‚")

        # æ­¥éª¤ 4: åˆ›å»ºå¹¶å‘æå–ä»»åŠ¡æ‰¹æ¬¡
        print(f"\næ­¥éª¤ 4: å°†ä¸ºæ¯ä¸ªå‚è€ƒæ–‡çŒ®åˆ›å»ºä¸€ä¸ªç‹¬ç«‹çš„å¹¶å‘åˆ†æä»»åŠ¡...")
        extraction_tasks = []
        extraction_batches_info = []
        for i in range(0, total_refs, BATCH_SIZE):
            batch_of_refs = all_references[i:i + BATCH_SIZE]
            task = agent.run_extraction_batch(
                full_latex_source=full_latex_content,
                references_batch=batch_of_refs,
            )
            extraction_tasks.append(task)
            extraction_batches_info.append(batch_of_refs)

        # æ­¥éª¤ 5: å¹¶å‘æ‰§è¡Œæ‰€æœ‰ä¸Šä¸‹æ–‡æå–ä»»åŠ¡ (è·å–JSONæ•°æ®)
        print(f"\næ­¥éª¤ 5: æ­£åœ¨å¹¶å‘æ‰§è¡Œ {len(extraction_tasks)} ä¸ªè¯¦ç»†åˆ†æä»»åŠ¡ (ç”ŸæˆJSON)...")
        structured_data_chunks = await asyncio.gather(*extraction_tasks)
        print("âœ… æ‰€æœ‰æå–æ‰¹æ¬¡åˆ†æå®Œæˆã€‚")

        # åˆå¹¶æ‰€æœ‰æ‰¹æ¬¡çš„ç»“æœï¼Œå¹¶å¤„ç†å¤±è´¥çš„æ‰¹æ¬¡
        final_data_map = {ref['key']: ref for ref in all_references}

        for i, chunk in enumerate(structured_data_chunks):
            batch_info = extraction_batches_info[i]
            if chunk is None:  # å¦‚æœ run_extraction_batch è¿”å› None è¡¨ç¤ºå¤±è´¥
                start_key = batch_info[0]['key']
                end_key = batch_info[-1]['key']
                print(f"   â””â”€â”€ âš ï¸ å‚è€ƒæ–‡çŒ® {start_key} åˆ†æå¤±è´¥ï¼Œå°†åœ¨æŠ¥å‘Šä¸­æ ‡è®°ã€‚")
                for ref in batch_info:
                    final_data_map[ref['key']]['analysis_failed'] = True
                continue

            for result in chunk.get("analysis_results", []):
                key = result.get('key')
                if key in final_data_map:
                    final_data_map[key].update(result)

        # æ­¥éª¤ 6: ä»ç»“æ„åŒ–æ•°æ®æ¸²æŸ“HTMLæŠ¥å‘Šå¹¶ä¿å­˜
        print("\næ­¥éª¤ 6: æ­£åœ¨ä»ç»“æ„åŒ–æ•°æ®æ¸²æŸ“å¹¶ä¿å­˜æœ€ç»ˆçš„HTMLæŠ¥å‘Š...")
        full_html_content = render_html_from_data(list(final_data_map.values()))
        header = HTML_HEADER.format(title=paper_title)
        footer = HTML_FOOTER.format(timestamp=datetime.now().strftime("%Y-%m-%d %H:%M:%S"))
        final_html_report = header + full_html_content + footer
        file_writer.save_html_report(final_html_report, OUTPUT_HTML_FILE)

        # æ­¥éª¤ 7: æ„å»ºå¹¶è¿”å›æœ€ç»ˆçš„ç»“æ„åŒ–æ•°æ®
        output_reference_data = []
        for key, data in final_data_map.items():
            sections = sorted(list(set(
                citation.get('section', 'Unknown Section') for citation in data.get('citations', [])
            )))
            output_reference_data.append({
                "key": key,
                "title": data.get("title", "Title not found"),
                "sections": sections
            })

        print(f"\nğŸ‰ å·¥ä½œæµç¨‹å®Œæˆï¼è¯·åœ¨æµè§ˆå™¨ä¸­æ‰“å¼€ '{OUTPUT_HTML_FILE}' æŸ¥çœ‹æŠ¥å‘Šã€‚")
        return output_reference_data

    except Exception as e:
        print(f"\nâŒ å‘ç”Ÿæ„å¤–çš„è‡´å‘½é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        return []


if __name__ == "__main__":
    reference_data = asyncio.run(main())

    if reference_data:
        print("\n--- æå–å‡ºçš„å‚è€ƒæ–‡çŒ®ä»£å·ã€æ ‡é¢˜ä¸å¼•ç”¨ç« èŠ‚æ˜ å°„ ---")
        print(f"å˜é‡ç±»å‹: {type(reference_data)}")
        print(f"æ€»æ•°: {len(reference_data)}")

        print("\nå†…å®¹é¢„è§ˆ:")
        for item in reference_data[:10]:
            sections_str = ", ".join(item.get('sections', ['N/A']))
            if not sections_str: sections_str = "æ— æœ‰æ•ˆå¼•ç”¨"
            print(f"  - {item['key']}: {item['title']}")
            print(f"    â””â”€â”€ å¼•ç”¨ç« èŠ‚: {sections_str}")
    else:
        print("\n--- æœªèƒ½æå–å‡ºä»»ä½•å‚è€ƒæ–‡çŒ®æ•°æ®ã€‚ ---")